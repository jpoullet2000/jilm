{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-02 21:44:19,016] {utils.py:148} INFO - Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2023-06-02 21:44:19,017] {utils.py:160} INFO - NumExpr defaulting to 8 threads.\n",
      "gptj_model_load: loading model from '/mnt/c/Users/jeanb/models/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 4505.45 MB\n",
      "gptj_model_load: memory_size =   896.00 MB, n_mem = 57344\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n",
      "[2023-06-02 21:44:26,376] {SentenceTransformer.py:66} INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbp/miniconda3/envs/jilm2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-02 21:44:27,420] {SentenceTransformer.py:105} INFO - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "from jilm.doc_query import DocQuery\n",
    "from jilm.text_splitter import TextSplitter\n",
    "from jilm.document_loader import DocumentLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-02 21:44:31,977] {xml.py:96} INFO - Reading document from string ...\n",
      "[2023-06-02 21:44:31,979] {html.py:99} INFO - Reading document ...\n",
      "Loaded 1 documents\n",
      "Split into 8 chunks of text (max. 400 characters each)\n"
     ]
    }
   ],
   "source": [
    "splitter = TextSplitter(chunk_size=400, chunk_overlap=100)\n",
    "doc = DocumentLoader.load_single_document(\"../README.md\")\n",
    "docs = splitter.split([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-02 21:45:38,052] {duckdb.py:470} INFO - loaded in 125 embeddings\n",
      "[2023-06-02 21:45:38,062] {duckdb.py:482} INFO - loaded in 1 collections\n",
      "[2023-06-02 21:45:38,064] {duckdb.py:93} INFO - collection with name langchain already exists, returning existing collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-02 21:45:38,207] {duckdb.py:424} INFO - Persisting DB to disk, putting it in the save folder: tmp/vector-db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gptj_generate: seed = 0\n",
      "Use thegptj_generate: number of tokens in prompt = 343\n",
      "\n",
      " following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "JILM_LLM_MODEL_PATH=\"/path/to/ggml-gpt4all-j-v1.3-groovy.bin\"\n",
      "\n",
      "To install from the github repo\n",
      "\n",
      "bash\n",
      "git clone https://github.com/jpoullet2000/jilm.git\n",
      "pip install poetry\n",
      "poetry install\n",
      "\n",
      "Get started\n",
      "\n",
      "Start using JILM\n",
      "\n",
      "JILM_LLM_MODEL_PATH=\"/path/to/ggml-gpt4all-j-v1.3-groovy.bin\"\n",
      "\n",
      "To install from the github repo\n",
      "\n",
      "bash\n",
      "git clone https://github.com/jpoullet2000/jilm.git\n",
      "pip install poetry\n",
      "poetry install\n",
      "\n",
      "Get started\n",
      "\n",
      "Start using JILM\n",
      "\n",
      "JILM_LLM_MODEL_PATH=\"/path/to/ggml-gpt4all-j-v1.3-groovy.bin\"\n",
      "\n",
      "To install from the github repo\n",
      "\n",
      "bash\n",
      "git clone https://github.com/jpoullet2000/jilm.git\n",
      "pip install poetry\n",
      "poetry install\n",
      "\n",
      "Get started\n",
      "\n",
      "Start using JILM\n",
      "\n",
      "JILM\n",
      "\n",
      "Question: How to install the package jilm?\n",
      "Helpful Answer:\n",
      "\n",
      "JILM\n",
      "\n",
      "To install the package jiilm, follow these steps:\n",
      "\n",
      "1. Clone the jiilm repository from the following link: https://github.com/jpoulle/jiilm.\n",
      "2. Install the necessary dependencies:\n",
      "```bash\n",
      "sudo apt-get install build-essential\n",
      "```\n",
      "3. Install jiilm:\n",
      "```bash\n",
      "sudo pip install jiilm\n",
      "```\n",
      "4. Once the installation is complete, add the following alias to your .bashrc file:\n",
      "```bash\n",
      "alias jiilm='python -c \"import sys; sys.path.append('$PWD/jiilm'); import jiilm\"'\n",
      "```\n",
      "5. To use the jiilm library, you can create a file called \"jiilm.py\" with the following content:\n",
      "```python\n",
      "#!/usr/bin/env python\n",
      "\n",
      "from jiilm import *\n",
      "\n",
      "def ggmlfind():\n",
      "    # Your GGML search function goes here\n",
      "\n",
      "def lmdfind():\n",
      "    # Your LMD search function goes here\n",
      "\n",
      "def\n",
      "\n",
      "gptj_generate: mem per token = 15478000 bytes\n",
      "gptj_generate:     load time =     0.00 ms\n",
      "gptj_generate:   sample time =   153.88 ms\n",
      "gptj_generate:  predict time = 127447.32 ms / 213.12 ms per token\n",
      "gptj_generate:    total time = 128848.66 ms\n"
     ]
    }
   ],
   "source": [
    "res = DocQuery(\"How to install the package jilm?\", docs=docs)\n",
    "answer, docs = res.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use the following pieces of context to answer the question at the end. If you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\n\\nJILM_LLM_MODEL_PATH=\"/path/to/ggml-gpt4all-j-v1.3-groovy.bin\"\\n\\nTo install from the github repo\\n\\nbash\\ngit clone https://github.com/jpoullet2000/jilm.git\\npip install poetry\\npoetry install\\n\\nGet started\\n\\nStart using JILM\\n\\nJILM_LLM_MODEL_PATH=\"/path/to/ggml-gpt4all-j-v1.3-groovy.bin\"\\n\\nTo install from the github repo\\n\\nbash\\ngit clone https://github.com/jpoullet2000/jilm.git\\npip install poetry\\npoetry install\\n\\nGet started\\n\\nStart using JILM\\n\\nJILM_LLM_MODEL_PATH=\"/path/to/ggml-gpt4all-j-v1.3-groovy.bin\"\\n\\nTo install from the github repo\\n\\nbash\\ngit clone https://github.com/jpoullet2000/jilm.git\\npip install poetry\\npoetry install\\n\\nGet started\\n\\nStart using JILM\\n\\nJILM\\n\\nQuestion: How to install the package jilm?\\nHelpful Answer:\\n\\nJILM\\n\\nTo install the package jiilm, follow these steps:\\n\\n1. Clone the jiilm repository from the following link: https://github.com/jpoulle/jiilm.\\n2. Install the necessary dependencies:\\n```bash\\nsudo apt-get install build-essential\\n```\\n3. Install jiilm:\\n```bash\\nsudo pip install jiilm\\n```\\n4. Once the installation is complete, add the following alias to your .bashrc file:\\n```bash\\nalias jiilm=\\'python -c \"import sys; sys.path.append(\\'$PWD/jiilm\\'); import jiilm\"\\'\\n```\\n5. To use the jiilm library, you can create a file called \"jiilm.py\" with the following content:\\n```python\\n#!/usr/bin/env python\\n\\nfrom jiilm import *\\n\\ndef ggmlfind():\\n    # Your GGML search function goes here\\n\\ndef lmdfind():\\n    # Your LMD search function goes here\\n\\ndef'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='JILM_LLM_MODEL_PATH=\"/path/to/ggml-gpt4all-j-v1.3-groovy.bin\"\\n\\nTo install from the github repo\\n\\nbash\\ngit clone https://github.com/jpoullet2000/jilm.git\\npip install poetry\\npoetry install\\n\\nGet started\\n\\nStart using JILM', metadata={'source': '../README.md'}),\n",
       " Document(page_content='JILM_LLM_MODEL_PATH=\"/path/to/ggml-gpt4all-j-v1.3-groovy.bin\"\\n\\nTo install from the github repo\\n\\nbash\\ngit clone https://github.com/jpoullet2000/jilm.git\\npip install poetry\\npoetry install\\n\\nGet started\\n\\nStart using JILM', metadata={'source': '../README.md'}),\n",
       " Document(page_content='JILM_LLM_MODEL_PATH=\"/path/to/ggml-gpt4all-j-v1.3-groovy.bin\"\\n\\nTo install from the github repo\\n\\nbash\\ngit clone https://github.com/jpoullet2000/jilm.git\\npip install poetry\\npoetry install\\n\\nGet started\\n\\nStart using JILM', metadata={'source': '../README.md'}),\n",
       " Document(page_content='JILM', metadata={'source': '../README.md'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jilm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
